{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução Teórica"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PySpark é uma biblioteca de processamento distribuído de dados em larga escala. Ele fornece uma interface em Python para a estrutura de processamento de dados distribuída Apache Spark, permitindo que usuários executem operações de processamento de grandes conjuntos de dados em clusters distribuídos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cheat Sheet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align = \"center\">\n",
    "<img src = \"https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1625837623/PySpark_Cheat_Sheet-_Spark_in_Python_owornh.png\" width = 1500>\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primeiros passos com PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A versão atual do PySpark é: 3.4.0\n"
     ]
    }
   ],
   "source": [
    "import pyspark as spark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "print(f\"A versão atual do PySpark é: {spark.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x000002B9C5619210>\n"
     ]
    }
   ],
   "source": [
    "# Cria ou recupera uma sessão Spark\n",
    "my_spark = SparkSession.builder.getOrCreate()\n",
    "print(my_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista de todas as tabelas no cluster atual: []\n"
     ]
    }
   ],
   "source": [
    "# Retorna o nome de todas as tabelas dentro do clusters em uma lista\n",
    "print(f\"Lista de todas as tabelas no cluster atual: {my_spark.catalog.listTables()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos carregar o DataFrame Iris:\n",
    "iris_df = pd.read_csv(\n",
    "    r\"G:\\Meu Drive\\Data Science\\Dados\\Classificação\\Iris\\Iris.csv\"\n",
    ")\n",
    "\n",
    "iris_df.drop('Id', axis = 1, inplace = True)\n",
    "\n",
    "iris_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string, _c5: string]\n"
     ]
    }
   ],
   "source": [
    "# Caso queiramos carregar utilizando PySpark, podemos fazer da seguinte forma:\n",
    "\n",
    "iris_spark = my_spark.createDataFrame(iris_df) # Cria um DataFrame Spark a partir de um DataFrame do Pandas\n",
    "\n",
    "# ou\n",
    "\n",
    "iris_spark = my_spark.read.csv(\n",
    "    r\"G:\\Meu Drive\\Data Science\\Dados\\Classificação\\Iris\\Iris.csv\"\n",
    ")\n",
    "\n",
    "# Podemos ver o tipo de dados de cada coluna:\n",
    "print(iris_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "|_c0|          _c1|         _c2|          _c3|         _c4|        _c5|\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|\n",
      "|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|\n",
      "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n",
      "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|\n",
      "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Para visualizar as primeiras linhas do DataFrame, podemos utilizar o método show():\n",
    "iris_spark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista de todas as tabelas no cluster atual: [Table(name='iris', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]\n"
     ]
    }
   ],
   "source": [
    "# Adiciona a tabela ao catálogo do cluster atual:\n",
    "iris_spark.createOrReplaceTempView(\"iris\")\n",
    "\n",
    "print(f\"Lista de todas as tabelas no cluster atual: {my_spark.catalog.listTables()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza uma QUERY SQL em uma tabela do cluster.\n",
    "query = \"\"\n",
    "query_df = my_spark.sql(query)\n",
    "query_df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulando Colunas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=EMACjF6eCU4&ab_channel=Stack retomar no tempo 17min \n",
    "\n",
    "https://www.youtube.com/watch?v=8esz7IWSbMM&ab_channel=AprenderDados%7CBernardoCambruzzi assistir\n",
    "\n",
    "https://community.cloud.databricks.com/?o=4566189763914988#notebook/3855061166299265 notebook no databricks\n",
    "\n",
    "https://www.youtube.com/playlist?list=PLIHpLBNsiHE3Zmdc8Hc8H8n8TVpmrb-fp playlist de engenharia de dados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
