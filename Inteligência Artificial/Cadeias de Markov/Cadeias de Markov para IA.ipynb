{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cadeias de Markov"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chamamos uma matriz $M$ de **matriz de transição** se ela possui as probabilidades de transição entre pares de estado para um determinado problema.\n",
    "\n",
    "> Um processo estocástico $\\left\\{ X_n \\right\\}$ é uma cadeira de Markov se a probabilidade do (n+1)-ésimo evento depende apenas da probabilidade do n-ésimo evento:\n",
    ">\n",
    "> $$ P(X_{n+1}, |X_0,\\dots, X_n) = P(X_{n+1}| X_n)$$\n",
    ">\n",
    "> Isto é, as probabilidades de transição entre estados não se alteram ao decorrer do tempo.\n",
    "\n",
    "Em algumas situações, quando $n$ é muito grande, a probabilidade de estados independe do estado inicial - quando isto acontece, temos uma **distribuição estacionária**.\n",
    "\n",
    "Podemos considerar a distribuição estacionária como sendo o momento em que a probabilidade entre os estados não é mais alterada, por exemplo:\n",
    "\n",
    "$$ M^{(n+1)} = M^n.$$\n",
    "\n",
    "sendo formal, consideramos um vetor m-dimensional $\\pi=(\\pi_1, \\pi_2, \\dots, \\pi_m)$ e queremos resolver o sistema\n",
    "\n",
    "$$ \\pi = \\pi M, \\sum_{j=1,m} \\pi_j = 1.$$\n",
    "\n",
    "- $\\pi_j$ representa a probabilidade de se estar no j-ésimo estado após uma quantidade grande de passos.\n",
    "\n",
    "> A distribuição estacionária pode não ser obtida por uma série de problemas, dentre eles:\n",
    "> - Erros em estimar $M$;\n",
    "> - Probabilidades podem se alterar ao decorrer do tempo\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
