{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matriz de Confusão para Classificação Multiclasse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para problemas de classificação multiclasse também podemos definir a matriz de confusão. Para um exemplo com $k$ classes, com a segunda classe sendo a referência temos:\n",
    "\n",
    "<p align=\"center\"> <img src=\"Matriz de Confusão Multiclasse.png\" width=\"800\"> </p>\n",
    "\n",
    "Neste caso de generalização, temos certos cuidados. Para cada classe $j$, temos:\n",
    "\n",
    "- $\\text{TP}_j$: Quantidade de elementos da $j$-ésima classe corretamente classificados;\n",
    "- $\\text{TN}_j$: Quantidade de elementos que não pertencem e não foram previstos a $j$-ésima classe;\n",
    "- $\\text{FN}_j$: Quantidade de elemento $j$-ésima classe incorretamente classificados;\n",
    "- $\\text{FP}_j$: Quantidade de elementos previstos na $j-$ésima classe que foram incorretamente classificados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acurácia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acurácia é de longe a métrica mais fácil de ser definida quando o assunto é classificação multiclasse. Esta é nada mais do que a quantidade de elementos corretamente classificados pelo modelo:\n",
    "\n",
    "$$\\text{Acurácia} = \\frac{\\sum_{i=1}^k{\\text{TP}}_i}{n}.$$\n",
    "\n",
    "Onde $n$ é a quantidade de elementos na base de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisão pode ser definida para cada $j-$ésima classe da maneira usual:\n",
    "\n",
    "$$\\text{Precisão}_j = \\frac{\\text{TP}_j}{\\text{TP}_j + \\text{FP}_j}$$\n",
    "\n",
    "qual representa a quantidade de previsões da $j-$ésima classe corretamente realizadas.\n",
    "\n",
    "Além disso, podemos definir a precisão geral do modelo como sendo a média das precisões entre as $k$ classes:\n",
    "\n",
    "$$\\text{Precisão} = k^{-1} \\sum_{i=1}^k \\text{Precisão}_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall pode ser definido para cada $j-$ésima classe da maneira usual:\n",
    "\n",
    "$$\\text{Recall}_j = \\frac{\\text{TP}_j}{\\text{TP}_j + \\text{FN}_j}$$\n",
    "\n",
    "qual representa a quantidade de elementos da $j-$ésima classe corretamente classificados.\n",
    "\n",
    "Além disso, podemos definir o recall geral do modelo como sendo a média dos recalls entre as $k$ classes:\n",
    "\n",
    "$$\\text{Recall} = k^{-1} \\sum_{i=1}^k \\text{Recall}_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1-Score do modelo possuí a mesma definição que para o caso binário, sendo as médias geométricas da precisão e recall do modelo:\n",
    "\n",
    "$$\\text{F1-Score} = \\frac{2 \\text{Precisão} \\cdot \\text{Recall}}{\\text{Precisão + \\text{Recall}}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC-ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De longe a métrica mais difícil de generalizar quando o assunto é classificação multiclasse. Existem duas abordagens possíveis que comentaremos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OvR - One vs Rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para um problema com $k$ classes o método OvR consiste em subdividir o problema em $k$ problemas binários:\n",
    "\n",
    "1. Para cada $j-$ésima classe, dividimos a base em evento (quando a classe j ocorre) e não evento (caso contrário);\n",
    "2. Calculamos o AUC para cada problema binário;\n",
    "3. O AUC do modelo é a média dos AUCs observados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OvO - One vs One"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para um problema com $k$ classes o método OvO consiste em observar todas as classes entre si e então considerar essas comparações como eventos binários:\n",
    "\n",
    "1. Para cada $i-$ésima e $j-$ésima classe, dividimos a base em evento (quando a classe j ocorre) e não evento (quando a classe i ocorre). Elementos que não pertencem a nenhuma das duas classes são descartados;\n",
    "2. Calculamos o AUC para as classes em questão;\n",
    "3. O AUC do modelo é a média dos AUCs observados.\n",
    "\n",
    "Neste caso, cada classe é considerada tanto quanto um evento como um não evento quando analisamos todos os cenários possíveis, levando a uma quantidade muito grande de AUCs para serem analisados.\n",
    "\n",
    "- Se temos 3 classes, então temos 6 OvO scores;\n",
    "- Se temos 4 classes, então temos 12 OvO Scores;\n",
    "- Se temos $k$ classes, então temos $k!$ OvO Scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências\n",
    "\n",
    "- [Multiclass classification evaluation with ROC Curves and ROC AUC](https://towardsdatascience.com/multiclass-classification-evaluation-with-roc-curves-and-roc-auc-294fd4617e3a)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
